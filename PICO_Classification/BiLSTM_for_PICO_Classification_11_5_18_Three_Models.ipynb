{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM for PICO Classification 11/5/18 Three Models",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnc1231/ResearchNotebooks/blob/master/PICO_Classification/BiLSTM_for_PICO_Classification_11_5_18_Three_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XMVpzGDj1JSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f6814e2f-f4a0-4115-953c-c48c4ad7364b"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bepnye/EBM-NLP.git\n",
        "!tar -xzf EBM-NLP/ebm_nlp_1_00.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EBM-NLP'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 106 (delta 0), reused 4 (delta 0), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (106/106), 38.52 MiB | 10.12 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OKvjZMquMyMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pip Stuff"
      ]
    },
    {
      "metadata": {
        "id": "jG3VR9Rxv00y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pip stuff\n",
        "\n",
        "!pip -qqq install gensim\n",
        "!pip -qqq install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip -qqq install --upgrade keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3YDT5tKM3Vp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Python setup"
      ]
    },
    {
      "metadata": {
        "id": "0h3JNl6gvmuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ac19edfd-fc5c-44de-c7e6-75612440f9fb"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, LSTM, Bidirectional, TimeDistributed, Reshape, Dropout\n",
        "from keras_contrib.layers import CRF\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hhC2H98k62VW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "eb01d967-6fa5-4790-c2a8-0b46e0b33ce2"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TslFRkWsNAN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Paths"
      ]
    },
    {
      "metadata": {
        "id": "3oHwhzTzEsU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir = 'ebm_nlp_1_00'\n",
        "spans_dir = os.path.join(base_dir, 'annotations/aggregated/starting_spans')\n",
        "participants_dir = os.path.join(spans_dir, 'participants')\n",
        "participants_training_dir = os.path.join(participants_dir, 'train')\n",
        "interventions_dir = os.path.join(spans_dir, 'interventions')\n",
        "interventions_training_dir = os.path.join(interventions_dir, 'train')\n",
        "outcomes_dir = os.path.join(spans_dir, 'outcomes')\n",
        "outcomes_training_dir = os.path.join(outcomes_dir, 'train')\n",
        "\n",
        "\n",
        "documents_dir = os.path.join(base_dir, 'documents')\n",
        "embedding_path = \"/content/drive/My Drive/Colab Notebooks/Research/PubMed-w2v.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8p1A9ICnNHRa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "max_abstract_len = 400\n",
        "max_num_tokens = 30000\n",
        "embedding_dimension = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3hA6oiv-2FCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training data:\n",
        "training_ids = [filename.split('_')[0] for filename in os.listdir(participants_training_dir) if filename.endswith('.ann')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elGa2F0-6Jag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2382f7c3-e1c4-4693-97f4-166471eff9f3"
      },
      "cell_type": "code",
      "source": [
        "def tokens_and_labels(ids):\n",
        "  all_participant_labels = []\n",
        "  all_interventions_labels = []\n",
        "  all_outcomes_labels = []\n",
        "  \n",
        "  abstract_lengths = []\n",
        "  all_tokens = []\n",
        "  all_labels = []\n",
        "    \n",
        "  for id in ids:\n",
        "    with open(os.path.join(documents_dir, id + \".tokens\")) as tokens_file:\n",
        "      unlimited_tokens = tokens_file.read().split(\" \")\n",
        "      abstract_lengths.append(len(unlimited_tokens))\n",
        "      tokens = unlimited_tokens[:max_abstract_len]\n",
        "      all_tokens.append(tokens)\n",
        "  \n",
        "    with open(os.path.join(participants_training_dir, id + \"_AGGREGATED.ann\")) as annotations_file:\n",
        "      participant_labels = [int(label) for label in annotations_file.read().split(\",\")[:max_abstract_len]]\n",
        "      all_participant_labels.append(participant_labels)\n",
        "      \n",
        "    with open(os.path.join(interventions_training_dir, id + \"_AGGREGATED.ann\")) as annotations_file:\n",
        "      interventions_labels = [int(label) for label in annotations_file.read().split(\",\")[:max_abstract_len]]\n",
        "      all_interventions_labels.append(interventions_labels)\n",
        "      \n",
        "    with open(os.path.join(outcomes_training_dir, id + \"_AGGREGATED.ann\")) as annotations_file:\n",
        "      outcomes_labels = [int(label) for label in annotations_file.read().split(\",\")[:max_abstract_len]]\n",
        "      all_outcomes_labels.append(outcomes_labels)\n",
        "      \n",
        "  \n",
        "  return (all_tokens, all_participant_labels, all_interventions_labels, all_outcomes_labels, abstract_lengths)\n",
        "        \n",
        "(all_tokens, all_participant_labels, all_intervention_labels, all_outcome_labels, abstract_lengths) = tokens_and_labels(training_ids)\n",
        "\n",
        "\n",
        "# Need to get the max_num_tokens most common tokens\n",
        "counter = Counter()\n",
        "\n",
        "for tokens in all_tokens:\n",
        "  counter.update(tokens)\n",
        "\n",
        "# Leave space for reserved tokens when we do mapping\n",
        "most_common_tokens = counter.most_common(max_num_tokens)   \n",
        "num_regular_tokens = len(most_common_tokens) #Extra 2 for the unk token and the blank token.\n",
        "num_tokens = num_regular_tokens + 2\n",
        "unk_token = num_tokens - 2\n",
        "blank_token = num_tokens - 1\n",
        "print(\"Found {} distinct words\".format(num_regular_tokens))\n",
        "print(\"25th percentile abstract length is {}\".format(np.percentile(abstract_lengths, 25)))\n",
        "print(\"95th percentile abstract length is {}\".format(np.percentile(abstract_lengths, 95)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30000 distinct words\n",
            "25th percentile abstract length is 206.0\n",
            "95th percentile abstract length is 438.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ONXOcSui1eug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Need a word to index mapping\n",
        "word_to_index = {word_count_pair[0]:index for index, word_count_pair in enumerate(most_common_tokens)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fs7Aznw1NwMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creating embedding matrix\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bG6x3dY0QZpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Embedding data\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(datapath(embedding_path), binary=True)  # C binary format\n",
        "#Get average vector in space.\n",
        "average_vec = np.mean(wv_from_bin.vectors, axis=0).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_K5nKN7aP31G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb10fac4-815c-49fc-8650-0dd95b2cac19"
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros(shape=(num_tokens, embedding_dimension))\n",
        "count_of_unknowns = 0\n",
        "for i in range(0, num_regular_tokens):\n",
        "  token = most_common_tokens[i][0]\n",
        "  if token in wv_from_bin: #Ignoring words not in vocab\n",
        "    embedding_matrix[i] = wv_from_bin[token]\n",
        "  else:\n",
        "    embedding_matrix[i] = np.copy(average_vec)\n",
        "    count_of_unknowns += 1\n",
        "\n",
        "print(\"There were {} unknown tokens\".format(count_of_unknowns))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fBOowxeHOCGK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creating vectors of token indicies"
      ]
    },
    {
      "metadata": {
        "id": "trUQeKuZ56tg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now I need to make a vector where the words are replaced with numbers. \n",
        "all_tokens_indices =[]\n",
        "\n",
        "for tokens in all_tokens:\n",
        "  all_tokens_indices.append([word_to_index.get(token, unk_token) for token in tokens])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDsn0add7hOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "079ab051-b200-4621-9bb8-255daa73ddfc"
      },
      "cell_type": "code",
      "source": [
        "count_of_unks = 0;\n",
        "count_of_tokens = 0;\n",
        "for token_indices in all_tokens_indices:\n",
        "  for index in token_indices:\n",
        "    count_of_tokens += 1\n",
        "    if index == unk_token:\n",
        "      count_of_unks += 1\n",
        "\n",
        "print(count_of_tokens)\n",
        "print(count_of_unks)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271581\n",
            "21525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e7xYM3GNGUaT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Participants"
      ]
    },
    {
      "metadata": {
        "id": "fOwAiEVG_YRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "participants_x_train = []\n",
        "participants_y_train = []\n",
        "\n",
        "participants_x_train = keras.preprocessing.sequence.pad_sequences(all_tokens_indices, maxlen=max_abstract_len, value = blank_token)\n",
        "participants_y_train = keras.preprocessing.sequence.pad_sequences(all_participant_labels, maxlen=max_abstract_len, value = 0.0)\n",
        "\n",
        "participants_x_val = participants_x_train[4000:]\n",
        "participants_y_val = participants_y_train[4000:]\n",
        "\n",
        "participants_x_train = participants_x_train[:4000]\n",
        "participants_y_train = participants_y_train[:4000]\n",
        "\n",
        "participants_crf_y_train = (np.arange(participants_y_train.max() + 1) == participants_y_train[...,None]).astype(int)\n",
        "participants_crf_y_val = (np.arange(participants_y_val.max() + 1) == participants_y_val[...,None]).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nbq23bWN2rsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "930bf8fa-fa98-484e-cac7-a9c350b991a6"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_tokens,\n",
        "                    embedding_dimension,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_abstract_len,\n",
        "                    trainable=True))\n",
        "model.add(Bidirectional(LSTM(180, return_sequences=True)))\n",
        "model.add(Dropout(.7))\n",
        "model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
        "crf = CRF(2)\n",
        "model.add(crf)\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 400, 200)          6000400   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 400, 360)          548640    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 400, 360)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 400, 128)          46208     \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 400, 2)            266       \n",
            "=================================================================\n",
            "Total params: 6,595,514\n",
            "Trainable params: 6,595,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zqL1gOqZJThv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=crf.loss_function,\n",
        "              metrics=[crf.accuracy])\n",
        "history = model.fit(participants_x_train, participants_crf_y_train, epochs = 3, batch_size = 64, validation_data=(participants_x_val, participants_crf_y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1UX77us6tUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67b86581-4d20-435f-9432-71d20114af11"
      },
      "cell_type": "code",
      "source": [
        "participants_val_predictions = model.predict(participants_x_val)\n",
        "participants_val_predictions_indexed = np.argmax(participants_val_predictions, axis=2)\n",
        "participants_val_predictions_flat = participants_val_predictions_indexed.flatten()\n",
        "participants_val_actual_flat = participants_y_val.flatten()\n",
        "computed_f1_score = f1_score(participants_val_actual_flat, participants_val_predictions_flat)\n",
        "computed_precision = precision_score(participants_val_actual_flat, participants_val_predictions_flat)\n",
        "computed_recall = recall_score(participants_val_actual_flat, participants_val_predictions_flat)\n",
        "\n",
        "print(\"F1 Score: {} Precision: {} Recall: {}\".format(computed_f1_score, computed_precision, computed_recall))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6985229881554621 Precision: 0.799953466728711 Recall: 0.6199199451876961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X4ZaZ_ONGI1k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Interventions"
      ]
    },
    {
      "metadata": {
        "id": "hng9RX5IGLk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interventions_x_train = []\n",
        "interventions_y_train = []\n",
        "\n",
        "interventions_x_train = keras.preprocessing.sequence.pad_sequences(all_tokens_indices, maxlen=max_abstract_len, value = blank_token)\n",
        "interventions_y_train = keras.preprocessing.sequence.pad_sequences(all_participant_labels, maxlen=max_abstract_len, value = 0.0)\n",
        "\n",
        "interventions_x_val = interventions_x_train[4000:]\n",
        "interventions_y_val = interventions_y_train[4000:]\n",
        "\n",
        "interventions_x_train = interventions_x_train[:4000]\n",
        "interventions_y_train = interventions_y_train[:4000]\n",
        "\n",
        "interventions_crf_y_train = (np.arange(interventions_y_train.max() + 1) == interventions_y_train[...,None]).astype(int)\n",
        "interventions_crf_y_val = (np.arange(interventions_y_val.max() + 1) == interventions_y_val[...,None]).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ee0X5SaGinQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "d7adfb1d-1e6f-455e-d1b2-7a832353f25f"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_tokens,\n",
        "                    embedding_dimension,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_abstract_len,\n",
        "                    trainable=True))\n",
        "model.add(Bidirectional(LSTM(180, return_sequences=True)))\n",
        "model.add(Dropout(.7))\n",
        "model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
        "crf = CRF(2)\n",
        "model.add(crf)\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 400, 200)          6000400   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 400, 360)          548640    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 400, 360)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 400, 128)          46208     \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 400, 2)            266       \n",
            "=================================================================\n",
            "Total params: 6,595,514\n",
            "Trainable params: 6,595,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fYgs8z0wGv9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2ffffc62-67b8-417e-ba3c-3887432e7f94"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=crf.loss_function,\n",
        "              metrics=[crf.accuracy])\n",
        "history = model.fit(interventions_x_train, interventions_crf_y_train, epochs = 3, batch_size = 64, validation_data=(interventions_x_val, interventions_crf_y_val))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 802 samples\n",
            "Epoch 1/3\n",
            "4000/4000 [==============================] - 201s 50ms/step - loss: 0.3227 - acc: 0.8953 - val_loss: 0.1956 - val_acc: 0.9412\n",
            "Epoch 2/3\n",
            "4000/4000 [==============================] - 197s 49ms/step - loss: 0.1774 - acc: 0.9460 - val_loss: 0.1703 - val_acc: 0.9489\n",
            "Epoch 3/3\n",
            "4000/4000 [==============================] - 199s 50ms/step - loss: 0.1483 - acc: 0.9546 - val_loss: 0.1738 - val_acc: 0.9463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6IRjFLGpG0Hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "384cf82e-43f0-426e-f0e6-4bde5d719ada"
      },
      "cell_type": "code",
      "source": [
        "interventions_val_predictions = model.predict(interventions_x_val)\n",
        "interventions_val_predictions_indexed = np.argmax(interventions_val_predictions, axis=2)\n",
        "interventions_val_predictions_flat = interventions_val_predictions_indexed.flatten()\n",
        "interventions_val_actual_flat = interventions_y_val.flatten()\n",
        "computed_f1_score = f1_score(interventions_val_actual_flat, interventions_val_predictions_flat)\n",
        "computed_precision = precision_score(interventions_val_actual_flat, interventions_val_predictions_flat)\n",
        "computed_recall = recall_score(interventions_val_actual_flat, interventions_val_predictions_flat)\n",
        "\n",
        "print(\"F1 Score: {} Precision: {} Recall: {}\".format(computed_f1_score, computed_precision, computed_recall))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score: 0.680953527570431 Precision: 0.7000533170843172 Recall: 0.6628682701669611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b_QdXmdFIjJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Outcomes"
      ]
    },
    {
      "metadata": {
        "id": "dh8VDWH6G1yH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outcomes_x_train = []\n",
        "outcomes_y_train = []\n",
        "\n",
        "outcomes_x_train = keras.preprocessing.sequence.pad_sequences(all_tokens_indices, maxlen=max_abstract_len, value = blank_token)\n",
        "outcomes_y_train = keras.preprocessing.sequence.pad_sequences(all_participant_labels, maxlen=max_abstract_len, value = 0.0)\n",
        "\n",
        "outcomes_x_val = outcomes_x_train[4000:]\n",
        "outcomes_y_val = outcomes_y_train[4000:]\n",
        "\n",
        "outcomes_x_train = outcomes_x_train[:4000]\n",
        "outcomes_y_train = outcomes_y_train[:4000]\n",
        "\n",
        "outcomes_crf_y_train = (np.arange(outcomes_y_train.max() + 1) == outcomes_y_train[...,None]).astype(int)\n",
        "outcomes_crf_y_val = (np.arange(outcomes_y_val.max() + 1) == outcomes_y_val[...,None]).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69BQG3SDImTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "5a3b2899-2955-4af0-9965-5498317c5c5f"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_tokens,\n",
        "                    embedding_dimension,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_abstract_len,\n",
        "                    trainable=True))\n",
        "model.add(Bidirectional(LSTM(180, return_sequences=True)))\n",
        "model.add(Dropout(.7))\n",
        "model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
        "crf = CRF(2)\n",
        "model.add(crf)\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 400, 200)          6000400   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 400, 360)          548640    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 400, 360)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 400, 128)          46208     \n",
            "_________________________________________________________________\n",
            "crf_4 (CRF)                  (None, 400, 2)            266       \n",
            "=================================================================\n",
            "Total params: 6,595,514\n",
            "Trainable params: 6,595,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XKQ99s_yIqz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bba1e1a1-40db-44e4-db5c-85217c8cab26"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=crf.loss_function,\n",
        "              metrics=[crf.accuracy])\n",
        "history = model.fit(outcomes_x_train, outcomes_crf_y_train, epochs = 3, batch_size = 64, validation_data=(outcomes_x_val, outcomes_crf_y_val))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 802 samples\n",
            "Epoch 1/3\n",
            "4000/4000 [==============================] - 205s 51ms/step - loss: 0.1227 - acc: 0.9390 - val_loss: 0.0971 - val_acc: 0.9482\n",
            "Epoch 2/3\n",
            "4000/4000 [==============================] - 202s 50ms/step - loss: 0.0884 - acc: 0.9532 - val_loss: 0.0872 - val_acc: 0.9527\n",
            "Epoch 3/3\n",
            "4000/4000 [==============================] - 202s 50ms/step - loss: 0.0749 - acc: 0.9590 - val_loss: 0.0854 - val_acc: 0.9513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n2CznUolJDgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc54f2ba-1134-4110-96c5-406c80b339a8"
      },
      "cell_type": "code",
      "source": [
        "outcomes_val_predictions = model.predict(outcomes_x_val)\n",
        "outcomes_val_predictions_indexed = np.argmax(outcomes_val_predictions, axis=2)\n",
        "outcomes_val_predictions_flat = outcomes_val_predictions_indexed.flatten()\n",
        "outcomes_val_actual_flat = outcomes_y_val.flatten()\n",
        "computed_f1_score = f1_score(outcomes_val_actual_flat, outcomes_val_predictions_flat)\n",
        "computed_precision = precision_score(outcomes_val_actual_flat, outcomes_val_predictions_flat)\n",
        "computed_recall = recall_score(outcomes_val_actual_flat, outcomes_val_predictions_flat)\n",
        "\n",
        "print(\"F1 Score: {} Precision: {} Recall: {}\".format(computed_f1_score, computed_precision, computed_recall))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7076986337214735 Precision: 0.7345956852397951 Recall: 0.6827016696116259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "avD5cDZcMbm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}